import json
import asyncio
import uuid
from datetime import datetime
from typing import Optional, Set
from contextlib import asynccontextmanager

import websockets
import clickhouse_connect
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Query
from fastapi.responses import JSONResponse, FileResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from sqlalchemy import text

from config import settings
from database import engine, get_db
from routers import (
    auth_router,
    keys_router,
    competitions_router,
    trading_router,
    admin_router
)
from services.matching_engine import process_ticker_for_matching
from database import async_session
from cache import init_cache, get_cache
from models.competition import Competition
from sqlalchemy import select, update

# ClickHouse ì„¤ì •
CH_HOST = settings.CLICKHOUSE_HOST
CH_PORT = settings.CLICKHOUSE_PORT
CH_USER = settings.CLICKHOUSE_USER
CH_PASSWORD = settings.CLICKHOUSE_PASSWORD
CH_DATABASE = settings.CLICKHOUSE_DATABASE

# Upbit WebSocket
UPBIT_WS_URL = "wss://api.upbit.com/websocket/v1"
CODES = settings.SUPPORTED_CODES

# ì „ì—­ ìƒíƒœ
ch_client = None
connected_clients: Set[WebSocket] = set()
subscriptions: dict[WebSocket, Set[str]] = {}  # í´ë¼ì´ì–¸íŠ¸ë³„ êµ¬ë… ì½”ë“œ
postgres_available = False  # PostgreSQL ì—°ê²° ìƒíƒœ

# í†µê³„
stats = {"total_received": 0, "total_broadcast": 0}


def get_ch_client():
    global ch_client
    if ch_client is None:
        ch_client = clickhouse_connect.get_client(
            host=CH_HOST,
            port=CH_PORT,
            username=CH_USER,
            password=CH_PASSWORD,
            database=CH_DATABASE
        )
    return ch_client


async def broadcast(data: dict):
    """êµ¬ë…í•œ í´ë¼ì´ì–¸íŠ¸ë“¤ì—ê²Œ ë°ì´í„° ì „ì†¡"""
    code = data.get("code", "")
    message = json.dumps(data, default=str)

    disconnected = set()
    for client in connected_clients:
        # í•´ë‹¹ ì½”ë“œë¥¼ êµ¬ë…í•œ í´ë¼ì´ì–¸íŠ¸ì—ê²Œë§Œ ì „ì†¡
        client_subs = subscriptions.get(client, set())
        if not client_subs or code in client_subs:  # ë¹ˆ setì´ë©´ ì „ì²´ êµ¬ë…
            try:
                await client.send_text(message)
                stats["total_broadcast"] += 1
            except:
                disconnected.add(client)

    # ëŠê¸´ í´ë¼ì´ì–¸íŠ¸ ì œê±°
    for client in disconnected:
        connected_clients.discard(client)
        subscriptions.pop(client, None)


async def update_competition_statuses():
    """ëŒ€íšŒ ìƒíƒœ ìë™ ì—…ë°ì´íŠ¸ (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)

    - pending + start_time ì§€ë‚¨ â†’ active
    - active + end_time ì§€ë‚¨ â†’ ended
    """
    while True:
        try:
            await asyncio.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì²´í¬

            async with async_session() as db:
                now = datetime.utcnow()

                # pending â†’ active (ì‹œì‘ ì‹œê°„ ì§€ë‚¨)
                await db.execute(
                    update(Competition)
                    .where(
                        Competition.status == "pending",
                        Competition.start_time <= now
                    )
                    .values(status="active")
                )

                # active â†’ ended (ì¢…ë£Œ ì‹œê°„ ì§€ë‚¨)
                await db.execute(
                    update(Competition)
                    .where(
                        Competition.status == "active",
                        Competition.end_time < now
                    )
                    .values(status="ended")
                )

                await db.commit()

        except Exception as e:
            print(f"âš ï¸ Competition status update error: {e}")


async def upbit_websocket_handler():
    """Upbit WebSocketì—ì„œ ë°ì´í„°ë¥¼ ë°›ì•„ ì²˜ë¦¬"""
    global postgres_available

    while True:
        try:
            async with websockets.connect(UPBIT_WS_URL) as ws:
                subscribe_msg = [
                    {"ticket": str(uuid.uuid4())},
                    {"type": "ticker", "codes": CODES},
                ]
                await ws.send(json.dumps(subscribe_msg))
                print("âœ… Upbit WebSocket connected")

                async for message in ws:
                    if isinstance(message, bytes):
                        message = message.decode("utf-8")

                    data = json.loads(message)
                    stats["total_received"] += 1

                    # í´ë¼ì´ì–¸íŠ¸ë“¤ì—ê²Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
                    await broadcast(data)

                    # ì§€ì •ê°€ ì£¼ë¬¸ ì²´ê²° í™•ì¸ (PostgreSQL ì—°ê²° ì‹œì—ë§Œ)
                    if postgres_available:
                        try:
                            async with async_session() as db:
                                await process_ticker_for_matching(db, data)
                        except Exception as me_err:
                            pass  # ë§¤ì¹­ ì—ëŸ¬ëŠ” ì¡°ìš©íˆ ë¬´ì‹œ

        except Exception as e:
            print(f"âŒ Upbit WebSocket error: {e}")
            await asyncio.sleep(1)


@asynccontextmanager
async def lifespan(app: FastAPI):
    global postgres_available

    # ì‹œì‘ ì‹œ
    get_ch_client()
    print("âœ… ClickHouse connected")

    # Redis ì—°ê²°
    redis_cache = await init_cache()

    # PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸
    try:
        async with engine.begin() as conn:
            await conn.execute(text("SELECT 1"))
        postgres_available = True
        print("âœ… PostgreSQL connected")
        print("âœ… Matching engine ready")
    except Exception as e:
        postgres_available = False
        print(f"âš ï¸ PostgreSQL connection failed: {e}")
        print("  Trading features will be disabled")

    # Upbit WebSocket íƒœìŠ¤í¬ ì‹œì‘
    ws_task = asyncio.create_task(upbit_websocket_handler())

    # ëŒ€íšŒ ìƒíƒœ ìë™ ì—…ë°ì´íŠ¸ íƒœìŠ¤í¬ ì‹œì‘
    competition_task = asyncio.create_task(update_competition_statuses())
    print("âœ… Competition status updater started")

    yield

    # ì¢…ë£Œ ì‹œ
    ws_task.cancel()
    competition_task.cancel()
    if redis_cache:
        await redis_cache.close()
    await engine.dispose()
    print("âœ… Connections closed")


app = FastAPI(
    title="Upbit Trading Competition API",
    description="ì‹¤ì‹œê°„ Upbit ì‹œì„¸ ë° ëª¨ì˜ íˆ¬ì ëŒ€íšŒ API",
    lifespan=lifespan,
    docs_url="/swagger",  # Swagger UIë¥¼ /swaggerë¡œ ì´ë™
    redoc_url="/redoc",   # ReDocì€ /redoc ìœ ì§€
    openapi_url="/openapi.json"
)

# CORS ë¯¸ë“¤ì›¨ì–´
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# API ë¼ìš°í„° ë“±ë¡
app.include_router(auth_router, prefix="/api/auth", tags=["auth"])
app.include_router(keys_router, prefix="/api/keys", tags=["keys"])
app.include_router(competitions_router, prefix="/api/competitions", tags=["competitions"])
app.include_router(trading_router, prefix="/api/trading", tags=["trading"])
app.include_router(admin_router, prefix="/api/admin", tags=["admin"])

# ì •ì  íŒŒì¼ ì„œë¹™
app.mount("/static", StaticFiles(directory="frontend"), name="static")


# ============ REST API ============

@app.get("/")
async def root():
    """í”„ë¡ íŠ¸ì—”ë“œ í˜ì´ì§€ ì„œë¹™"""
    return FileResponse("frontend/index.html")


@app.get("/competition")
@app.get("/competition/")
async def competition_page():
    """ëŒ€íšŒ ë©”ì¸ í˜ì´ì§€"""
    return FileResponse("frontend/competition/index.html")


@app.get("/competition/trading")
async def competition_trading_page():
    """íŠ¸ë ˆì´ë”© í˜ì´ì§€"""
    return FileResponse("frontend/competition/trading.html")


@app.get("/competition/leaderboard")
async def competition_leaderboard_page():
    """ë¦¬ë”ë³´ë“œ í˜ì´ì§€"""
    return FileResponse("frontend/competition/leaderboard.html")


@app.get("/docs")
async def api_docs_page():
    """API ë¬¸ì„œ í˜ì´ì§€"""
    return FileResponse("frontend/docs.html")


@app.get("/admin")
@app.get("/admin/")
async def admin_page():
    """ê´€ë¦¬ì í˜ì´ì§€"""
    return FileResponse("frontend/admin/index.html")


@app.get("/admin/competitions/{competition_id}")
async def admin_competition_detail_page(competition_id: str):
    """ê´€ë¦¬ì ëŒ€íšŒ ìƒì„¸ í˜ì´ì§€"""
    return FileResponse("frontend/admin/competition.html")


@app.get("/admin/participants/{participant_id}")
async def admin_participant_detail_page(participant_id: str):
    """ê´€ë¦¬ì ì°¸ê°€ì ìƒì„¸ í˜ì´ì§€"""
    return FileResponse("frontend/admin/participant.html")


@app.get("/api")
async def api_info():
    return {
        "message": "Upbit Trading Competition API",
        "market_data": {
            "GET /tickers": "ì‹œì„¸ ì¡°íšŒ (ê¸°ê°„/ì½”ë“œ í•„í„° ê°€ëŠ¥)",
            "GET /tickers/{code}": "íŠ¹ì • ì½”ë“œ ì‹œì„¸ ì¡°íšŒ",
            "GET /tickers/{code}/latest": "íŠ¹ì • ì½”ë“œ ìµœì‹  ì‹œì„¸",
            "GET /candles/{code}": "OHLCV ìº”ë“¤ ë°ì´í„°",
            "GET /codes": "ì €ì¥ëœ ì½”ë“œ ëª©ë¡",
            "WS /ws": "ì‹¤ì‹œê°„ WebSocket ìŠ¤íŠ¸ë¦¼"
        },
        "trading": {
            "POST /api/auth/register": "Clerk ì¸ì¦ í›„ ì‚¬ìš©ì ë“±ë¡",
            "POST /api/keys": "API Key ë°œê¸‰",
            "GET /api/competitions": "ëŒ€íšŒ ëª©ë¡",
            "POST /api/competitions/{id}/join": "ëŒ€íšŒ ì°¸ê°€",
            "GET /api/trading/balance": "ì”ê³  ì¡°íšŒ",
            "POST /api/trading/orders": "ì£¼ë¬¸ ìƒì„±",
            "GET /api/competitions/{id}/leaderboard": "ë¦¬ë”ë³´ë“œ"
        },
        "documentation": {
            "GET /docs": "API ê°€ì´ë“œ (ì¹œì ˆí•œ ì„¤ëª…)",
            "GET /swagger": "Swagger UI (ì¸í„°ë™í‹°ë¸Œ í…ŒìŠ¤íŠ¸)",
            "GET /redoc": "ReDoc (ë ˆí¼ëŸ°ìŠ¤ ë¬¸ì„œ)",
            "GET /openapi.json": "OpenAPI ìŠ¤í‚¤ë§ˆ"
        }
    }


@app.get("/tickers")
async def get_tickers(
    code: Optional[str] = Query(default=None, description="ì½”ë“œ í•„í„° (ì˜ˆ: KRW-BTC)"),
    start: Optional[str] = Query(default=None, description="ì‹œì‘ ì‹œê°„ (ì˜ˆ: 2026-01-09 00:00:00)"),
    end: Optional[str] = Query(default=None, description="ì¢…ë£Œ ì‹œê°„ (ì˜ˆ: 2026-01-09 23:59:59)"),
    limit: int = Query(default=100, le=10000, description="ìµœëŒ€ ì¡°íšŒ ìˆ˜")
):
    """
    ì‹œì„¸ ì¡°íšŒ (ê¸°ê°„ ì§€ì • ê°€ëŠ¥)

    - code: íŠ¹ì • ì½”ë“œë§Œ ì¡°íšŒ
    - start: ì‹œì‘ ì‹œê°„ (ISO í˜•ì‹ ë˜ëŠ” 'YYYY-MM-DD HH:MM:SS')
    - end: ì¢…ë£Œ ì‹œê°„
    - limit: ìµœëŒ€ ì¡°íšŒ ìˆ˜ (ê¸°ë³¸ 100, ìµœëŒ€ 10000)
    """
    client = get_ch_client()

    conditions = []
    params = {"limit": limit}

    if code:
        conditions.append("code = {code:String}")
        params["code"] = code
    if start:
        conditions.append("timestamp >= {start:String}")
        params["start"] = start
    if end:
        conditions.append("timestamp <= {end:String}")
        params["end"] = end

    where_clause = f"WHERE {' AND '.join(conditions)}" if conditions else ""

    result = client.query(f"""
        SELECT timestamp, code, trade_price, trade_volume, change, change_rate
        FROM upbit_ticker
        {where_clause}
        ORDER BY timestamp DESC
        LIMIT {{limit:UInt32}}
    """, parameters=params)

    return [
        {
            "timestamp": str(row[0]),
            "code": row[1],
            "trade_price": row[2],
            "trade_volume": row[3],
            "change": row[4],
            "change_rate": row[5]
        }
        for row in result.result_rows
    ]


@app.get("/tickers/{code}")
async def get_ticker_by_code(code: str, limit: int = Query(default=100, le=1000)):
    """íŠ¹ì • ì½”ë“œ ì‹œì„¸ ì¡°íšŒ"""
    client = get_ch_client()
    result = client.query("""
        SELECT timestamp, code, trade_price, trade_volume, change, change_rate
        FROM upbit_ticker
        WHERE code = {code:String}
        ORDER BY timestamp DESC
        LIMIT {limit:UInt32}
    """, parameters={"code": code, "limit": limit})

    return [
        {
            "timestamp": str(row[0]),
            "code": row[1],
            "trade_price": row[2],
            "trade_volume": row[3],
            "change": row[4],
            "change_rate": row[5]
        }
        for row in result.result_rows
    ]


@app.get("/tickers/{code}/latest")
async def get_latest_ticker(code: str):
    """íŠ¹ì • ì½”ë“œ ìµœì‹  ì‹œì„¸"""
    # ìºì‹œ í‚¤ ìƒì„±
    cache_key = f"ticker:latest:{code}"

    # ìºì‹œì—ì„œ ì¡°íšŒ
    cache = await get_cache()
    if cache and cache.is_connected:
        cached = await cache.get(cache_key)
        if cached:
            return cached

    client = get_ch_client()
    result = client.query("""
        SELECT timestamp, code, opening_price, high_price, low_price, trade_price,
               prev_closing_price, change, change_price, change_rate,
               trade_volume, acc_trade_volume_24h, acc_trade_price_24h
        FROM upbit_ticker
        WHERE code = {code:String}
        ORDER BY timestamp DESC
        LIMIT 1
    """, parameters={"code": code})

    if not result.result_rows:
        return JSONResponse(status_code=404, content={"error": "Not found"})

    row = result.result_rows[0]
    data = {
        "timestamp": str(row[0]),
        "code": row[1],
        "opening_price": row[2],
        "high_price": row[3],
        "low_price": row[4],
        "trade_price": row[5],
        "prev_closing_price": row[6],
        "change": row[7],
        "change_price": row[8],
        "change_rate": row[9],
        "trade_volume": row[10],
        "acc_trade_volume_24h": row[11],
        "acc_trade_price_24h": row[12]
    }

    # ìºì‹œì— ì €ì¥ (1ì´ˆ TTL)
    if cache and cache.is_connected:
        await cache.set(cache_key, data, settings.CACHE_TTL_TICKERS)

    return data


@app.get("/candles/{code}")
async def get_candles(
    code: str,
    interval: str = Query(default="1m", description="ê°„ê²© (1m, 5m, 15m, 1h, 1d)"),
    start: Optional[str] = Query(default=None, description="ì‹œì‘ ì‹œê°„"),
    end: Optional[str] = Query(default=None, description="ì¢…ë£Œ ì‹œê°„"),
    limit: int = Query(default=100, le=1000, description="ìµœëŒ€ ì¡°íšŒ ìˆ˜")
):
    """
    OHLCV ìº”ë“¤ ë°ì´í„° ì¡°íšŒ

    - interval: 1m(1ë¶„), 5m(5ë¶„), 15m(15ë¶„), 1h(1ì‹œê°„), 1d(1ì¼)
    """
    # ìºì‹œ í‚¤ ìƒì„±
    cache_key = f"candles:{code}:{interval}:{start}:{end}:{limit}"

    # ìºì‹œì—ì„œ ì¡°íšŒ
    cache = await get_cache()
    if cache and cache.is_connected:
        cached = await cache.get(cache_key)
        if cached:
            return cached

    client = get_ch_client()

    # interval to seconds
    interval_map = {
        "1m": 60,
        "5m": 300,
        "15m": 900,
        "1h": 3600,
        "1d": 86400
    }
    seconds = interval_map.get(interval, 60)

    conditions = ["code = {code:String}"]
    params = {"code": code, "limit": limit, "seconds": seconds}

    if start:
        conditions.append("timestamp >= {start:String}")
        params["start"] = start
    if end:
        conditions.append("timestamp <= {end:String}")
        params["end"] = end

    where_clause = f"WHERE {' AND '.join(conditions)}"

    result = client.query(f"""
        SELECT
            toStartOfInterval(timestamp, INTERVAL {{seconds:UInt32}} SECOND) as candle_time,
            argMin(trade_price, timestamp) as open,
            max(trade_price) as high,
            min(trade_price) as low,
            argMax(trade_price, timestamp) as close,
            sum(trade_volume) as volume,
            count() as trade_count
        FROM upbit_ticker
        {where_clause}
        GROUP BY candle_time
        ORDER BY candle_time DESC
        LIMIT {{limit:UInt32}}
    """, parameters=params)

    data = [
        {
            "time": str(row[0]),
            "open": row[1],
            "high": row[2],
            "low": row[3],
            "close": row[4],
            "volume": row[5],
            "trade_count": row[6]
        }
        for row in result.result_rows
    ]

    # ìºì‹œì— ì €ì¥ (5ì´ˆ TTL)
    if cache and cache.is_connected:
        await cache.set(cache_key, data, settings.CACHE_TTL_CANDLES)

    return data


@app.get("/candles/{code}/export")
async def export_candles(
    code: str,
    interval: str = Query(default="1m", description="ê°„ê²© (1m, 5m, 15m, 1h, 1d)"),
    start: Optional[str] = Query(default=None, description="ì‹œì‘ ì‹œê°„"),
    end: Optional[str] = Query(default=None, description="ì¢…ë£Œ ì‹œê°„"),
    format: str = Query(default="csv", description="í¬ë§· (csv, json)"),
    limit: int = Query(default=10000, le=100000, description="ìµœëŒ€ ì¡°íšŒ ìˆ˜")
):
    """
    OHLCV ìº”ë“¤ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ë¤í”„)

    - interval: 1m(1ë¶„), 5m(5ë¶„), 15m(15ë¶„), 1h(1ì‹œê°„), 1d(1ì¼)
    - format: csv ë˜ëŠ” json
    - limit: ìµœëŒ€ ì¡°íšŒ ìˆ˜ (ê¸°ë³¸ 10000, ìµœëŒ€ 100000)
    """
    client = get_ch_client()

    # interval to seconds
    interval_map = {
        "1m": 60,
        "5m": 300,
        "15m": 900,
        "1h": 3600,
        "1d": 86400
    }
    seconds = interval_map.get(interval, 60)

    conditions = ["code = {code:String}"]
    params = {"code": code, "limit": limit, "seconds": seconds}

    if start:
        conditions.append("timestamp >= {start:String}")
        params["start"] = start
    if end:
        conditions.append("timestamp <= {end:String}")
        params["end"] = end

    where_clause = f"WHERE {' AND '.join(conditions)}"

    result = client.query(f"""
        SELECT
            toStartOfInterval(timestamp, INTERVAL {{seconds:UInt32}} SECOND) as candle_time,
            argMin(trade_price, timestamp) as open,
            max(trade_price) as high,
            min(trade_price) as low,
            argMax(trade_price, timestamp) as close,
            sum(trade_volume) as volume,
            count() as trade_count
        FROM upbit_ticker
        {where_clause}
        GROUP BY candle_time
        ORDER BY candle_time ASC
        LIMIT {{limit:UInt32}}
    """, parameters=params)

    rows = [
        {
            "time": str(row[0]),
            "open": row[1],
            "high": row[2],
            "low": row[3],
            "close": row[4],
            "volume": row[5],
            "trade_count": row[6]
        }
        for row in result.result_rows
    ]

    if format == "json":
        return JSONResponse(
            content={"code": code, "interval": interval, "count": len(rows), "data": rows},
            headers={
                "Content-Disposition": f'attachment; filename="{code}_{interval}.json"'
            }
        )
    else:  # CSV
        import io
        import csv

        output = io.StringIO()
        writer = csv.writer(output)
        writer.writerow(["time", "open", "high", "low", "close", "volume", "trade_count"])
        for row in rows:
            writer.writerow([row["time"], row["open"], row["high"], row["low"], row["close"], row["volume"], row["trade_count"]])

        output.seek(0)
        return StreamingResponse(
            iter([output.getvalue()]),
            media_type="text/csv",
            headers={
                "Content-Disposition": f'attachment; filename="{code}_{interval}.csv"'
            }
        )


@app.get("/tickers/export")
async def export_tickers(
    code: Optional[str] = Query(default=None, description="ì½”ë“œ í•„í„° (ì˜ˆ: KRW-BTC)"),
    start: Optional[str] = Query(default=None, description="ì‹œì‘ ì‹œê°„"),
    end: Optional[str] = Query(default=None, description="ì¢…ë£Œ ì‹œê°„"),
    format: str = Query(default="csv", description="í¬ë§· (csv, json)"),
    limit: int = Query(default=10000, le=100000, description="ìµœëŒ€ ì¡°íšŒ ìˆ˜")
):
    """
    ì‹œì„¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ë¤í”„)

    - format: csv ë˜ëŠ” json
    - limit: ìµœëŒ€ ì¡°íšŒ ìˆ˜ (ê¸°ë³¸ 10000, ìµœëŒ€ 100000)
    """
    client = get_ch_client()

    conditions = []
    params = {"limit": limit}

    if code:
        conditions.append("code = {code:String}")
        params["code"] = code
    if start:
        conditions.append("timestamp >= {start:String}")
        params["start"] = start
    if end:
        conditions.append("timestamp <= {end:String}")
        params["end"] = end

    where_clause = f"WHERE {' AND '.join(conditions)}" if conditions else ""

    result = client.query(f"""
        SELECT timestamp, code, trade_price, trade_volume, change, change_rate,
               opening_price, high_price, low_price, prev_closing_price
        FROM upbit_ticker
        {where_clause}
        ORDER BY timestamp ASC
        LIMIT {{limit:UInt32}}
    """, parameters=params)

    rows = [
        {
            "timestamp": str(row[0]),
            "code": row[1],
            "trade_price": row[2],
            "trade_volume": row[3],
            "change": row[4],
            "change_rate": row[5],
            "opening_price": row[6],
            "high_price": row[7],
            "low_price": row[8],
            "prev_closing_price": row[9]
        }
        for row in result.result_rows
    ]

    filename_prefix = code.replace("-", "_") if code else "all_tickers"

    if format == "json":
        return JSONResponse(
            content={"count": len(rows), "data": rows},
            headers={
                "Content-Disposition": f'attachment; filename="{filename_prefix}.json"'
            }
        )
    else:  # CSV
        import io
        import csv

        output = io.StringIO()
        writer = csv.writer(output)
        writer.writerow(["timestamp", "code", "trade_price", "trade_volume", "change",
                        "change_rate", "opening_price", "high_price", "low_price", "prev_closing_price"])
        for row in rows:
            writer.writerow([row["timestamp"], row["code"], row["trade_price"], row["trade_volume"],
                           row["change"], row["change_rate"], row["opening_price"], row["high_price"],
                           row["low_price"], row["prev_closing_price"]])

        output.seek(0)
        return StreamingResponse(
            iter([output.getvalue()]),
            media_type="text/csv",
            headers={
                "Content-Disposition": f'attachment; filename="{filename_prefix}.csv"'
            }
        )


@app.get("/summary/{code}")
async def get_summary(
    code: str,
    start: Optional[str] = Query(default=None, description="ì‹œì‘ ì‹œê°„"),
    end: Optional[str] = Query(default=None, description="ì¢…ë£Œ ì‹œê°„")
):
    """ê¸°ê°„ ë‚´ ìš”ì•½ í†µê³„"""
    client = get_ch_client()

    conditions = ["code = {code:String}"]
    params = {"code": code}

    if start:
        conditions.append("timestamp >= {start:String}")
        params["start"] = start
    if end:
        conditions.append("timestamp <= {end:String}")
        params["end"] = end

    where_clause = f"WHERE {' AND '.join(conditions)}"

    result = client.query(f"""
        SELECT
            min(timestamp) as first_time,
            max(timestamp) as last_time,
            argMin(trade_price, timestamp) as first_price,
            argMax(trade_price, timestamp) as last_price,
            min(trade_price) as low_price,
            max(trade_price) as high_price,
            avg(trade_price) as avg_price,
            sum(trade_volume) as total_volume,
            count() as trade_count
        FROM upbit_ticker
        {where_clause}
    """, parameters=params)

    if not result.result_rows or result.result_rows[0][0] is None:
        return JSONResponse(status_code=404, content={"error": "No data found"})

    row = result.result_rows[0]
    first_price = row[2]
    last_price = row[3]
    price_change = last_price - first_price
    price_change_rate = (price_change / first_price * 100) if first_price else 0

    return {
        "code": code,
        "first_time": str(row[0]),
        "last_time": str(row[1]),
        "first_price": first_price,
        "last_price": last_price,
        "low_price": row[4],
        "high_price": row[5],
        "avg_price": row[6],
        "price_change": price_change,
        "price_change_rate": round(price_change_rate, 4),
        "total_volume": row[7],
        "trade_count": row[8]
    }


@app.get("/codes")
async def get_codes():
    """ì €ì¥ëœ ì½”ë“œ ëª©ë¡"""
    client = get_ch_client()
    result = client.query("""
        SELECT code, count() as cnt, max(timestamp) as last_update
        FROM upbit_ticker
        GROUP BY code
        ORDER BY cnt DESC
    """)

    return [
        {"code": row[0], "count": row[1], "last_update": str(row[2])}
        for row in result.result_rows
    ]


@app.get("/stats")
async def get_stats():
    """í†µê³„ ì¡°íšŒ"""
    client = get_ch_client()
    result = client.query("SELECT count() FROM upbit_ticker")
    total_rows = result.result_rows[0][0]

    return {
        "db_total_rows": total_rows,
        "ws_total_received": stats["total_received"],
        "ws_total_broadcast": stats["total_broadcast"],
        "ws_connected_clients": len(connected_clients)
    }


# ============ WebSocket API ============

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """
    ì‹¤ì‹œê°„ WebSocket ìŠ¤íŠ¸ë¦¼

    ì—°ê²° í›„ êµ¬ë…í•  ì½”ë“œë¥¼ JSONìœ¼ë¡œ ì „ì†¡:
    {"subscribe": ["KRW-BTC", "KRW-ETH"]}

    ì „ì²´ êµ¬ë…:
    {"subscribe": "all"}
    """
    await websocket.accept()
    connected_clients.add(websocket)
    subscriptions[websocket] = set()  # ë¹ˆ set = ì „ì²´ êµ¬ë…

    print(f"ğŸ“¡ Client connected. Total: {len(connected_clients)}")

    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° êµ¬ë… ë©”ì‹œì§€ ìˆ˜ì‹ 
            data = await websocket.receive_text()
            try:
                msg = json.loads(data)
                if "subscribe" in msg:
                    if msg["subscribe"] == "all":
                        subscriptions[websocket] = set()
                        await websocket.send_text(json.dumps({"status": "subscribed", "codes": "all"}))
                    else:
                        codes = set(msg["subscribe"])
                        subscriptions[websocket] = codes
                        await websocket.send_text(json.dumps({"status": "subscribed", "codes": list(codes)}))
            except json.JSONDecodeError:
                pass

    except WebSocketDisconnect:
        pass
    finally:
        connected_clients.discard(websocket)
        subscriptions.pop(websocket, None)
        print(f"ğŸ“¡ Client disconnected. Total: {len(connected_clients)}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
